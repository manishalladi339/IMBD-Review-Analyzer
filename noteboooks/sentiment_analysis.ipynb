{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import nltk\n",
    "\n",
    "# Download NLTK stopwords (if you plan to use it)\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Step 2: Load the data\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"data/movie_reviews.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n",
    "\n",
    "# Step 3: Data Preprocessing\n",
    "\n",
    "# Let's check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Remove any rows with missing reviews or sentiments\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert sentiment labels to numeric values (positive -> 1, negative -> 0)\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Step 4: Text Preprocessing\n",
    "\n",
    "# Convert reviews to lowercase to ensure uniformity\n",
    "df['review'] = df['review'].str.lower()\n",
    "\n",
    "# Remove punctuation and special characters (you can enhance this step)\n",
    "df['review'] = df['review'].str.replace('[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "\n",
    "# Remove stopwords (optional)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['review'] = df['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "# Step 5: Visualizing the data\n",
    "\n",
    "# Visualize the distribution of sentiments\n",
    "sns.countplot(x='sentiment', data=df)\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Feature Extraction (Text Vectorization)\n",
    "\n",
    "# Create a TfidfVectorizer to convert text to numerical features\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Split the data into features (X) and target labels (y)\n",
    "X = df['review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Convert text reviews into numerical features (TF-IDF)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Step 7: Train-Test Split\n",
    "\n",
    "# Split the data into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 8: Build and Train the Model\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Model Evaluation\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
